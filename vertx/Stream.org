* StreamBase
  ~Vertx~ 中比较重要的抽象.

** ReadStream

#+begin_src java
public interface ReadStream<T> extends StreamBase {
  /**
   * Set a data handler. As data is read, the handler will be called with the data.
   *
   * @return a reference to this, so the API can be used fluently
   */
  @Fluent
  ReadStream<T> handler(@Nullable Handler<T> handler);

  /**
   * Pause the {@code ReadStream}, it sets the buffer in {@code fetch} mode and clears the actual demand.
   * <p>
   * While it's paused, no data will be sent to the data {@code handler}.
   *
   * @return a reference to this, so the API can be used fluently
   */
  @Fluent
  ReadStream<T> pause();

  /**
   * Resume reading, and sets the buffer in {@code flowing} mode.
   * <p/>
   * If the {@code ReadStream} has been paused, reading will recommence on it.
   *
   * @return a reference to this, so the API can be used fluently
   */
  @Fluent
  ReadStream<T> resume();

  /**
   * Fetch the specified {@code amount} of elements. If the {@code ReadStream} has been paused, reading will
   * recommence with the specified {@code amount} of items, otherwise the specified {@code amount} will
   * be added to the current stream demand.
   *
   * @return a reference to this, so the API can be used fluently
   */
  @Fluent
  ReadStream<T> fetch(long amount);

  /**
   * Set an end handler. Once the stream has ended, and there is no more data to be read, this handler will be called.
   *
   * @return a reference to this, so the API can be used fluently
   */
  @Fluent
  ReadStream<T> endHandler(@Nullable Handler<Void> endHandler);
}
#+end_src


** WriteStream

#+begin_src java
public interface WriteStream<T> extends StreamBase {
  /**
   * Write some data to the stream.
   *
   * <p> The data is usually put on an internal write queue, and the write actually happens
   * asynchronously. To avoid running out of memory by putting too much on the write queue,
   * check the {@link #writeQueueFull} method before writing. This is done automatically if
   * using a {@link Pipe}.
   *
   * <p> When the {@code data} is moved from the queue to the actual medium, the returned
   * {@link Future} will be completed with the write result, e.g the future is succeeded
   * when a server HTTP response buffer is written to the socket and failed if the remote
   * client has closed the socket while the data was still pending for write.
   *
   * @param data  the data to write
   * @return a future completed with the write result
   */
  Future<Void> write(T data);

  /**
   * Same as {@link #write(T)} but with an {@code handler} called when the operation completes
   */
  void write(T data, Handler<AsyncResult<Void>> handler);

  /**
   * Ends the stream.
   * <p>
   * Once the stream has ended, it cannot be used any more.
   *
   * @return a future completed with the result
   */
  default Future<Void> end() {
    Promise<Void> promise = Promise.promise();
    end(promise);
    return promise.future();
  }

  /**
   * Same as {@link #end()} but with an {@code handler} called when the operation completes
   */
  void end(Handler<AsyncResult<Void>> handler);

  /**
   * Same as {@link #end()} but writes some data to the stream before ending.
   *
   * @implSpec The default default implementation calls sequentially {@link #write(Object)} then {@link #end()}
   * @apiNote Implementations might want to perform a single operation
   * @param data the data to write
   * @return a future completed with the result
   */
  default Future<Void> end(T data) {
    Promise<Void> provide = Promise.promise();
    end(data, provide);
    return provide.future();
  }

  /**
   * Same as {@link #end(T)} but with an {@code handler} called when the operation completes
   */
  default void end(T data, Handler<AsyncResult<Void>> handler) {
    if (handler != null) {
      write(data, ar -> {
        if (ar.succeeded()) {
          end(handler);
        } else {
          handler.handle(ar);
        }
      });
    } else {
      end(data);
    }
  }

  /**
   * Set the maximum size of the write queue to {@code maxSize}. You will still be able to write to the stream even
   * if there is more than {@code maxSize} items in the write queue. This is used as an indicator by classes such as
   * {@link Pipe} to provide flow control.
   * <p/>
   * The value is defined by the implementation of the stream, e.g in bytes for a
   * {@link io.vertx.core.net.NetSocket}, etc...
   *
   * @param maxSize  the max size of the write stream
   * @return a reference to this, so the API can be used fluently
   */
  @Fluent
  WriteStream<T> setWriteQueueMaxSize(int maxSize);

  /**
   * This will return {@code true} if there are more bytes in the write queue than the value set using {@link
   * #setWriteQueueMaxSize}
   *
   * @return {@code true} if write queue is full
   */
  boolean writeQueueFull();

  /**
   * Set a drain handler on the stream. If the write queue is full, then the handler will be called when the write
   * queue is ready to accept buffers again. See {@link Pipe} for an example of this being used.
   *
   * <p> The stream implementation defines when the drain handler, for example it could be when the queue size has been
   * reduced to {@code maxSize / 2}.
   *
   * @param handler the handler
   * @return a reference to this, so the API can be used fluently
   */
  @Fluent
  WriteStream<T> drainHandler(@Nullable Handler<Void> handler);
}
#+end_src

*** drainHandler

